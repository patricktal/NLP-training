{"cells":[{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":1536,"status":"ok","timestamp":1605779815666,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"},"user_tz":-240},"id":"6EUwaBVmPbLq"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":1520,"status":"ok","timestamp":1605779819559,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"},"user_tz":-240},"id":"Q4v1aylIjY_x"},"outputs":[],"source":["assert hasattr(tf, \"function\")"]},{"cell_type":"markdown","metadata":{"id":"M9LlLe7GvH3J"},"source":["**Open and process data**"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2489,"status":"ok","timestamp":1605779823171,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"},"user_tz":-240},"id":"iyxEkmBWvOol","outputId":"74fa95cd-bbbf-443e-c1b8-a4384089014a"},"outputs":[{"name":"stdout","output_type":"stream","text":["127286\n","Parce que, jargonnant vêpres, jeûne et vigile,\n","Exploitant Dieu qui rêve au fond du firmament,\n","Vous avez, au milieu du divin évangile,\n","Ouvert boutique effrontément ;\n","\n","Parce que vous feriez prendre à Jésus la verge,\n","Cyniques brocanteurs sortis on ne sait d'où ;\n","Parce que vous allez vendant la sainte vierge\n","Dix sous avec miracle, et sans miracle un sou ;\n","\n","Parce que vous contez d'effroyables sornettes\n","Qui font des temples saints trembler les vieux piliers ;\n","Parce que votre style éblouit les lunettes\n"]}],"source":["with open(\"data/victorhugo.txt\", \"r\" ) as f:\n","  text = f.read()\n","\n","print(len(text))\n","print(text[:500])"]},{"cell_type":"markdown","metadata":{"id":"U9SPin3rzkjx"},"source":["On peut avoir deux approches, soit on génère le texte mot par mot ou alors lettre par lettre. Pour notre cas on va générer le texte lettre par lettre car le modèle est assez simple. En utilisant les mots la complexité sera plus grande car il y'a beaucoup de mots que de lettres. En effet avec les lettres on aura que 36 caractères à traiter."]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1647,"status":"ok","timestamp":1605779827660,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"},"user_tz":-240},"id":"c6UUbr3owqBP","outputId":"cf7846bf-86d3-4aaa-db1c-8dd5ae8555d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["51 ['\\n', ' ', '\"', \"'\", ',', '.', ':', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '«', '»', 'à', 'â', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'î', 'ï', 'ô', 'ù', 'û', 'œ', '–', '—']\n","parce que,\n"]}],"source":["\n","text = text.lower()\n","text = text.replace(\"2\", \"\")\n","text = text.replace(\"1\", \"\")\n","text = text.replace(\"8\", \"\")\n","text = text.replace(\"5\", \"\")\n","text = text.replace(\"\u003e\", \"\")\n","text = text.replace(\"\u003c\", \"\")\n","text = text.replace(\"!\", \"\")\n","text = text.replace(\";\", \"\")\n","text = text.replace(\"?\", \"\")\n","text = text.replace(\"$\", \"\")\n","text = text.replace(\"-\", \"\")\n","\n","text = text.strip()\n","\n","vocab = sorted(set(text)) \n","print(len(vocab), vocab)\n","print(text[:10])"]},{"cell_type":"markdown","metadata":{"id":"Qk90PkhzBwo_"},"source":[""]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":1510,"status":"ok","timestamp":1605779831981,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"},"user_tz":-240},"id":"k1lMG2si10DU"},"outputs":[],"source":["vocab_size = len(vocab)\n","\n","vocab_to_int = {l:i for i,l in enumerate(vocab)}\n","int_to_vocab = {i:l for l,i in enumerate(vocab)}\n"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1544,"status":"ok","timestamp":1605779835000,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"},"user_tz":-240},"id":"bMlxWi_y3NPU","outputId":"379fb601-b345-43c2-83e2-be015d318e83"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","vocab_to_int\n","  '\\n':   0,\n","  ' ' :   1,\n","  '\"' :   2,\n","  \"'\" :   3,\n","  ',' :   4,\n","  '.' :   5,\n","  ':' :   6,\n","  'a' :   7,\n","  'b' :   8,\n","  'c' :   9,\n","  ...\n","}\n","\n","{\n","int_to_vocab\n","  '\\n':   0,\n","  ' ' :   1,\n","  '\"' :   2,\n","  \"'\" :   3,\n","  ',' :   4,\n","  '.' :   5,\n","  ':' :   6,\n","  'a' :   7,\n","  'b' :   8,\n","  'c' :   9,\n","  ...\n","}\n"]}],"source":["print('{')\n","print(\"vocab_to_int\")\n","for char,_ in zip(vocab_to_int, range(10)):\n","    print('  {:4s}: {:3d},'.format(repr(char), vocab_to_int[char]))\n","print('  ...\\n}')\n","print()\n","print('{')\n","print(\"int_to_vocab\")\n","for char,_ in zip(int_to_vocab, range(10)):\n","    print('  {:4s}: {:3d},'.format(repr(char), int_to_vocab[char]))\n","print('  ...\\n}')"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1534,"status":"ok","timestamp":1605779839242,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"},"user_tz":-240},"id":"1fc9fQBc3Sng","outputId":"4b8e890f-dfa4-49a7-aa09-aaedb9f53296"},"outputs":[{"name":"stdout","output_type":"stream","text":["Texte non encodé : parce que, jargonnant vêpres, jeûne et vigile,\n","exp\n","Texte encodé : [22, 7, 24, 9, 11, 1, 23, 27, 11, 4, 1, 16, 7, 24, 13, 21, 20, 20, 7, 20, 26, 1, 28, 41, 22, 24, 11, 25, 4, 1, 16, 11, 47, 20, 11, 1, 11, 26, 1, 28, 15, 13, 15, 18, 11, 4, 0, 11, 30, 22]\n"]}],"source":["encoded = [vocab_to_int[char] for char in text]\n","encoded_sentence = encoded[:50]\n","\n","print(\"Texte non encodé :\", text[:50])\n","print(\"Texte encodé :\", encoded_sentence)"]},{"cell_type":"markdown","metadata":{"id":"PQubhJWlMNQ0"},"source":["Génération des batchs (lots) pour l'entrainement"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1694,"status":"ok","timestamp":1605779845235,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"},"user_tz":-240},"id":"U_BkXNm0FNw-","outputId":"78b8cad2-bbc4-43db-d524-ba9ffd5c4eb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Inputs [22, 7, 24, 9, 11, 1, 23, 27, 11, 4]\n","Targets [7, 24, 9, 11, 1, 23, 27, 11, 4, 1]\n"]}],"source":["inputs, targets = encoded, encoded[1:]\n","\n","print(\"Inputs\", inputs[:10])\n","print(\"Targets\", targets[:10])"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"elapsed":1534,"status":"ok","timestamp":1605779848321,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"},"user_tz":-240},"id":"zAZ1fj8rMy_v","outputId":"45288530-ba68-42f3-b6db-f1864c65ab9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[22.  7. 24.  9. 11.] [ 7. 24.  9. 11.  1.]\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'for batch_inputs, batch_targets in gen_batch(inputs, targets, 5, 32, noise=30):\\n  print(batch_inputs[0], batch_targets[0])\\n  break'"]},"execution_count":32,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["#Fonction utilisée pour générer des batchs \n","\n","def gen_batch(inputs, targets, seq_length, batch_size, noise=0):\n","  #batch_size: la taille des lots souhaités de taille fixe\n","  #inputs: phrase en entrée, seq_length: la taille des séquences\n","  chunk_size = (len(inputs) - 1) // batch_size\n","\n","  #nombre de sequence par chunk\n","  sequences_per_chunk = chunk_size // seq_length #4 per chunk dans l'exemple\n","\n","  for s in range(0, sequences_per_chunk):\n","    batch_inputs = np.zeros((batch_size, seq_length))\n","    batch_targets = np.zeros((batch_size, seq_length))\n","    for b in range(0, batch_size):\n","      fr = (b * chunk_size) + (s * seq_length)\n","      to = fr + seq_length\n","      batch_inputs[b] = inputs[fr:to]\n","      batch_targets[b] = inputs[fr+1:to+1]\n","\n","      if noise \u003e 0: \n","        noise_indices = np.random.choice(seq_length, noise)\n","        batch_inputs[b][noise_indices] = np.random.randint(0, vocab_size)\n","\n","      yield batch_inputs, batch_targets\n","\n","for batch_inputs, batch_targets in gen_batch(inputs, targets, 5, 32, noise=0):\n","  print(batch_inputs[0], batch_targets[0])\n","  break\n","\n","\"\"\"for batch_inputs, batch_targets in gen_batch(inputs, targets, 5, 32, noise=30):\n","  print(batch_inputs[0], batch_targets[0])\n","  break\"\"\""]},{"cell_type":"markdown","metadata":{"id":"sReZ_DCnUuAV"},"source":["We can also use tensorflow to generate batch \n","\n","Pour ce faire, utilisez d'abord la fonction tf.data.Dataset.from_tensor_slices pour convertir le vecteur de texte en un flux d'indices de caractères.\n","\n","\n"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6985,"status":"ok","timestamp":1605779926709,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"},"user_tz":-240},"id":"cDyVNuIhU87l","outputId":"803a362b-e363-4d7c-e441-b1fc2f9c49f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["p\n","a\n","r\n","c\n","e\n"]}],"source":["# The maximum length sentence you want for a single input in characters\n","seq_len = 100\n","examples_per_epoch = len(text)//(seq_len+1)\n","\n","# Creating a mapping from unique characters to indices\n","char2idx = {u:i for i, u in enumerate(vocab)}\n","idx2char = np.array(vocab)\n","\n","text_as_int = np.array([char2idx[c] for c in text])\n","\n","# Create training examples / targets\n","char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n","\n","for i in char_dataset.take(5):\n","    print(idx2char[i.numpy()])"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1442,"status":"ok","timestamp":1605779933675,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"},"user_tz":-240},"id":"6jU6QttnVJ6r","outputId":"c6009621-8fe1-4af0-e72b-7cf0497e6b3b"},"outputs":[{"name":"stdout","output_type":"stream","text":["'parce que, jargonnant vêpres, jeûne et vigile,\\nexploitant dieu qui rêve au fond du firmament,\\nvous av'\n","'ez, au milieu du divin évangile,\\nouvert boutique effrontément \\n\\nparce que vous feriez prendre à jésus'\n","\" la verge,\\ncyniques brocanteurs sortis on ne sait d'où \\nparce que vous allez vendant la sainte vierge\"\n","\"\\ndix sous avec miracle, et sans miracle un sou \\n\\nparce que vous contez d'effroyables sornettes\\nqui fo\"\n","'nt des temples saints trembler les vieux piliers \\nparce que votre style éblouit les lunettes\\ndes duèg'\n"]}],"source":["sequences = char_dataset.batch(seq_len+1, drop_remainder=True)\n","\n","for item in sequences.take(5):\n","    print(repr(''.join(idx2char[item.numpy()])))"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1541,"status":"ok","timestamp":1605779937860,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"},"user_tz":-240},"id":"5E60PvGaW9oU","outputId":"c0fe6798-f85b-46ed-be84-3384ba2fb7bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input data:  'parce que, jargonnant vêpres, jeûne et vigile,\\nexploitant dieu qui rêve au fond du firmament,\\nvous a'\n","Target data: 'arce que, jargonnant vêpres, jeûne et vigile,\\nexploitant dieu qui rêve au fond du firmament,\\nvous av'\n"]}],"source":["def split_input_target(chunk):\n","    input_text = chunk[:-1]\n","    target_text = chunk[1:]\n","    return input_text, target_text\n","\n","dataset = sequences.map(split_input_target)\n","\n","for input_example, target_example in  dataset.take(1):\n","    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n","    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"]},{"cell_type":"markdown","metadata":{"id":"0vKKlt2RbiPD"},"source":["\n","One Hot encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sVzbnz19boJr"},"outputs":[],"source":["#create a personnalize layer using tensorflow layer\n","#depth : number of caracters, in this case we have 51\n","class OneHot(tf.keras.layers.Layer):\n","  def __init__(self, depth, **kwargs):\n","    super(OneHot, self).__init__(**kwargs)\n","    self.depth = depth\n","\n","  def call(self, x, mask=None):\n","    return tf.one_hot(tf.cast(x, tf.int32), self.depth)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Zfl5FsNIcyYW"},"outputs":[{"name":"stdout","output_type":"stream","text":["(32, 50)\n","(32, 50, 51)\n","input letter :  22.0\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0.]\n"]}],"source":["class RnnModel(tf.keras.Model):\n","  def __init__(self, vocab_size):\n","    super(RnnModel, self).__init__()\n","    self.one_hot = OneHot(len(vocab))\n","\n","  def call(self, inputs):\n","    output = self.one_hot(inputs)\n","    return output\n","\n","batch_inputs, batch_targets = next(gen_batch(inputs, targets, 50, 32))\n","\n","print(batch_inputs.shape)\n","model = RnnModel(len(vocab))\n","\n","output = model.predict(batch_inputs)\n","\n","print(output.shape)\n","\n","\n","print(\"input letter : \", batch_inputs[0][0])\n","print(output[0][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6DOulLLlaM2"},"outputs":[],"source":["# Batch size\n","BATCH_SIZE = 64\n","\n","# Buffer size to shuffle the dataset\n","# (TF data is designed to work with possibly infinite sequences,\n","# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n","# it maintains a buffer in which it shuffles elements).\n","BUFFER_SIZE = 10000\n","\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","\n","dataset"]},{"cell_type":"markdown","metadata":{"id":"EbMBjcGzrR6K"},"source":["Construisons notre modèle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mSB89h7FrYhm"},"outputs":[],"source":["vocab_size = len(vocab)\n","\n","#Create the layers\n","\n","  #Set the input of the model\n","tf_inputs = tf.keras.Input(shape=(None,), batch_size=64)\n","#convert each value of the input into a one encoding vector\n","\n","one_hot = OneHot(len(vocab))(tf_inputs)\n","\n","#stack LSTM cells\n","rnn_layer1 = tf.keras.layers.LSTM(128, return_sequences=True, stateful=True)(one_hot)\n","#return_sequences à true permet de récuperer toutes les sorties de la couche, s'il est à false on récupère seulement la dernière sortie\n","#stateful permet de ne pas reinitialiser l'état à 0 mais plutôt au dernier état précédent\n","rnn_layer2 = tf.keras.layers.LSTM(128, return_sequences=True, stateful=True)(rnn_layer1)\n","\n","#Create the outputs of the model\n","hiden_layer = tf.keras.layers.Dense(128, activation=\"relu\")(rnn_layer2)\n","outputs = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")(hiden_layer) \n","#Sotfmax pour avoir une distribution de probabilité sur toutes les lettres du vocabulaire\n","\n","#Set up the model\n","model = tf.keras.Model(inputs=tf_inputs, outputs=outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-RNxNIWFtb28"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"tVE0S773ylQD"},"source":["Set the loss and the objectives"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jkIJ7nSsyqIX"},"outputs":[],"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.Adam(lr=0.001)"]},{"cell_type":"markdown","metadata":{"id":"QTIQmlu52btq"},"source":["Set metrics to track the progress of the training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uk5rddXM2qur"},"outputs":[],"source":["#Loss\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","#Accuracy\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"]},{"cell_type":"markdown","metadata":{"id":"X-Tiqm_6086z"},"source":["Set the train method and the predict method "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_DwNes0-1ErG"},"outputs":[],"source":["@tf.function\n","def train_step(inputs, targets):\n","  with tf.GradientTape() as tape:\n","    #make a prediction on all the batch\n","    predictions = model(inputs)\n","    #Get the error/loss on these predictions\n","    loss = loss_object(targets, predictions)\n","  #Compute the gradient which respect to the loss\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  #Change the weights of the model\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","  #the metrics are accumulate over the time. You don't need to average it yourself\n","\n","  train_loss(loss)\n","  train_accuracy(targets, predictions)\n","\n","@tf.function\n","def predict(inputs):\n","  #Make a prediction on all the batch\n","  predictions = model(inputs)\n","  return predictions\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aW409fuz5FuK"},"source":["Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8q7EUVu_4_bs"},"outputs":[],"source":["model.reset_states()\n","\n","for epoch in range(5000):\n","  for batch_inputs, batch_targets in gen_batch(inputs, targets, 100, 64, noise=13): \n","    train_step(batch_inputs, batch_targets)\n","  template = '\\r, Epoch {}, Train Loss: {}, Train Accuracy: {}'\n","  print(template.format(epoch, train_loss.result(), train_accuracy.result()*100, end=\"\")\n","  model.reset_states()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Me8-hFH6a2G"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPPFSSDHgnrs1ft4UQSN+kA","name":"Text generator with simple RNN.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}