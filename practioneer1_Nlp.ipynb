{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"practioneer1_Nlp.ipynb","provenance":[{"file_id":"1FVErANVqwNQVcnsnkMzUv07ovB0Ud6tM","timestamp":1592473464455}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"QbkSHuxTLuVZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1592473523863,"user_tz":-180,"elapsed":4920,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"}},"outputId":"d9f2f50c-8310-48a7-887f-fded76bc6875"},"source":["! git clone  https://github.com/Jakobovski/free-spoken-digit-dataset "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'free-spoken-digit-dataset'...\n","remote: Enumerating objects: 9, done.\u001b[K\n","remote: Counting objects: 100% (9/9), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 3166 (delta 3), reused 8 (delta 3), pack-reused 3157\u001b[K\n","Receiving objects: 100% (3166/3166), 23.92 MiB | 23.55 MiB/s, done.\n","Resolving deltas: 100% (72/72), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vf4CIFeKNZBa","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592484794674,"user_tz":-180,"elapsed":1013,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"}}},"source":["from IPython.display import display, Audio\n","import librosa \n","import numpy as np"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"AZyBscRvN9a-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":75},"outputId":"3c1d33f7-0878-4fbc-8193-08719471f142"},"source":["display(Audio(filename=\"recordings/7_jackson_37.wav\", rate=1))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","                <audio controls=\"controls\" >\n","                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n","                    Your browser does not support the audio element.\n","                </audio>\n","              "],"text/plain":["<IPython.lib.display.Audio object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"dvXVao_K3VFH","colab_type":"code","colab":{}},"source":["! ls /content/free-spoken-digit-dataset/recordings/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wrSTzP1_2buB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592474386391,"user_tz":-180,"elapsed":999,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"}}},"source":["file_path = \"/content/free-spoken-digit-dataset/recordings/5_nicolas_14.wav\"\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"X4mqihJ70sb-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592474408181,"user_tz":-180,"elapsed":923,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"}}},"source":["samples, sample_rate = librosa.load(file_path)\n","for ts in [0.75, 1, 1.25]:\n","  for ps in [-1, 0, +1]:\n","    samples_new = librosa.effects.time_stretch(samples, rate=ts)\n","    y_new = librosa.effects.pitch_shift(samples_new, sample_rate, n_steps=ps)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"ILe3EYCibNaD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"status":"error","timestamp":1592484800355,"user_tz":-180,"elapsed":1023,"user":{"displayName":"patryck talom","photoUrl":"","userId":"03718126777161306514"}},"outputId":"cc85dbc9-72b4-4516-b9e1-a3b8ea641942"},"source":["max_length = 1.5 # Max length in seconds\n","samples, sample_rate = librosa.load(file_path)\n","short_samples = librosa.util.fix_length(samples, sample_rate*max_length)\n","\n","melSpectrum = librosa.feature.melspectrogram(short_samples.astype(np.float16), sr=sample_rate, n_mels=128)\n","\n","logMelSpectrogram = librosa.power_to_db(melSpectrum, ref=np.max)"],"execution_count":23,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-e4284e81288b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.5\u001b[0m \u001b[0;31m# Max length in seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshort_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmelSpectrum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshort_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/librosa/util/utils.py\u001b[0m in \u001b[0;36mfix_length\u001b[0;34m(data, size, axis, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpad\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpad_width\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'i'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`pad_width` must be of integral type.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;31m# Broadcast to shape (array.ndim, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: `pad_width` must be of integral type."]}]},{"cell_type":"code","metadata":{"id":"5MDxUKgAQyLH","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","\n","\n","#Pytorch Network Definition\n","class Model(nn.Module):\n","  def __init__(self):\n","    super(Model, self).__init__()\n","    self.fc1 = nn.Linear(3072, 128)\n","    self.fc2 = nn.Linear(128, 128)\n","    self.fc3 = nn.linear(128, 10)\n","\n","  def forward(self, x):\n","    x = x.view((-1, 3072))  #---converts 2D data to 1D\n","    h = self.fc1(x)\n","    h = torch.relu(h)\n","\n","    h = self.fc2(h)\n","    h = torch.relu(h)\n","\n","    h = self.fc3(h)\n","    out = torch.log_softmax(h, dim=1)\n","\n","    return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H7FysyYGcEFr","colab_type":"code","colab":{}},"source":["#Neural Network training in Pytorch\n","model = Model()\n","model.train()\n","\n","if use_cuda:\n","  model.cuda()\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","n_epoch = 40\n","\n","for epoch in range(n_epoch):\n","  for data, target in train_loader:\n","\n","    #Get Samples\n","    if use_cuda:\n","      data, target = data.cuda(), target.cuda()\n","\n","    #Clear Gradient \n","    optimizer.zero_grad()\n","    \n","    #Forward Propagation\n","    y_pred = model(data)\n","\n","    #Error Computation\n","    loss = torch.cross_entropy(y_pred, target)\n","\n","    #Back propagation\n","    loss.backward()\n","\n","    #parameter Update\n","    optimizer.step()\n","\n","# Modify the network to include some of the regularization techniques and activation functions such as,\n","# batch normalization, dropout, and ReLUs \n","\n","class Model2(nn.Module):\n","  def __init__(self):\n","    super(Model, self).__init__()\n","    self.fc1 = nn.Linear(3072, 128)\n","    self.bc1 = nn.BatchNorm1d(128)\n","\n","    self.fc2 = nn.Linear(128, 128)\n","    self.bc2 = nn.BatchNorm1d(128)\n","\n","    self.fc3 = nn.Linear(128, 10)\n","  \n","  def forward(self, x):\n","    x = x.view((-1, 3072))\n","    h = self.fc1(x)\n","    h = self.bc1(h)\n","    h = self.relu(h)\n","    h = F.dropout(h, p=0.5, training = self.training) # Disabled during evaluation\n","\n","    h = self.fc2(h)\n","    h = self.bc2(h)\n","    h = self.relu(h)\n","    h = F.dropout(h, p=0.2, training = self.training) # Disabled during evaluation\n","\n","    h = self.fc3(h)\n","    out = torch.log_softmax(h, dim=1)\n","\n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-jRsttJyj03l","colab_type":"code","colab":{}},"source":["# UNSUPERVISED LEARNING\n","\n","import torch.nn.functional as F\n","\n","#Pytorch Network Definition \n","\n","class autoencoder(nn.Module):\n","  def __init__(self):\n","    super(autoencoder, self).__init__()\n","    self.e_fc1 = nn.Linear(3072, 512)\n","    self.e_fc2 = nn.Linear(512, 128)\n","    self.e_fc3 = nn.Linear(128, 64)\n","    self.e_fc4 = nn.Linear(64, 64)\n","\n","    self.d_fc1 = nn.Linear(64, 64)\n","    self.d_fc2 = nn.Linear(128, 64)\n","    self.d_fc3 = nn.Linear(512, 128)\n","    self.d_fc4 = nn.Linear(3072, 512)\n","\n","  \n","  def forward(self, x):\n","    #Encoder\n","    h = F.relu(self.e_fc1(x))\n","    h = F.relu(self.e_fc2(h))\n","    h = F.relu(self.e_fc3(h))\n","    h = self.e_fc4(h)\n","\n","    #Decoder\n","    h = F.relu(self.d_fc1(h))\n","    h = F.relu(self.d_fc2(h))\n","    h = F.relu(self.d_fc3(h))\n","    h = self.d_fc4(h)\n","    out = F.tanh(h)\n","\n","    return out\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PPIZ6th90Fv4","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","\n","model = autoencoder()\n","optimizer = optim.Adam(model.parameters(), lr = learning_rate, weigth_decay = 1e-5)\n","\n","for epoch in range (n_epoch):\n","  for data, _ in train_loader:\n","    #Get Samples\n","\n","    input = data.view(-1, 3072) # we wil reuse the formatted input as our target\n","\n","    #Forward Propagation \n","    output = model(input)\n","\n","    #Error Computation \n","    loss = F.mse_loss(output, input)\n","\n","    #Clear Gradient \n","    optimizer.zero_grad()\n","\n","    #Backpropagation \n","    loss.backward()\n","\n","    #Parameter Update \n","    optimizer.step()\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OsJKJ9ishh12","colab_type":"code","colab":{}},"source":["# training with RBM code\n","\n","class RBM(nn.Module):\n","    def __init__(self, n_vis=3072, n_hin=128, k=5):\n","        super(RBM, self).__init__()\n","        self.W = nn.Parameter(torch.randn(n_hin, n_vis,)* 1e-2)\n","        self.v_bias = nn.Parameter(torch.zeros(n_vis))\n","        self.h_bias = nn.Parameter(torch.zeros(n_hin))\n","        self.k = k\n","\n","    def sample_from_p(self, p):\n","        return F.relu(torch.sign(P - Variable(torch.rand(p.size()))))\n","\n","    def v_to_h(self, v):\n","        p_h = F.sigmoid(F.linear(v, self.W, self.h_bias))\n","        sample_h = self.sample_from_p(p_h)\n","        return sample_h, p_h\n","\n","    def h_to_v(self, h):\n","        p_v = F.sigmoid(F.linear(h, self.W.t(), self.v_bias))\n","        sample_v = self.sample_from_p(p_v)\n","        return p_v, sample_v\n","\n","    def forward(self, v):\n","        pre_h1, h1 = self.v_to_h(v)\n","\n","        h_ = h1\n","        for _ in range (self.k):\n","        pre_v_, v_ = self.h_to_v(h_)\n","        pre_h_, h_ = self.v_to_h(v_)\n","\n","        return v, v_\n","\n","    def free_energy(self, v):\n","        vbias_term = v.mv(self.v_bias)\n","        wx_b = F.linear(v, self.W, self.h_bias)\n","        hidden_term = wx_b.exp().add(1).log().sum(1)\n","        return (- hidden_term - vbias_term).mean()\n","\n","\n","#Let's train the model with Adam\n","\n","rbm = RBM(n_vis=3072, n_hin=128, k = 1)\n","\n","train_op = optim.Adam(rbm.parameters(), 0.01)\n","\n","for epoch in range (epochs)\n","    loss_ = []\n","\n","    for _, (data, target) in enumerate (train_loader):\n","        data = Variable(data.view(-1, 3072))\n","        sample_data = data.bernoulli()\n","\n","        v, v1 = rbm(sample_data)\n","        loss = rbm.free_energy(v) - rbm.free_energy(v1)\n","        loss_.append(loss.data[0])\n","        train_op.zero_grad()\n","        loss.backward()\n","        train_op.step()\n","# After training our RBM features, we can create a logistic regression classifier to\n","# classify our examples based on the unsupervised features we have learned'\"\n","\n","\n","\n","from sklearn.linear_model import LogisticRegression\n","clf = LogisticRegression()\n","clf.fit(train_features, train_labels)\n","predictions = clf.predict(test_features)"],"execution_count":null,"outputs":[]}]}